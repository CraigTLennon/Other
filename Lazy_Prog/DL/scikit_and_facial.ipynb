{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"C:/Users/cLennon/Documents/GitHub/machine_learning_examples/ann_logistic_extra\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "def get_data(path=path):\n",
    "    df = pd.read_csv(path + '/ecommerce_data.csv')\n",
    "\n",
    "    # just in case you're curious what's in it\n",
    "    # df.head()\n",
    "\n",
    "    # easier to work with numpy array\n",
    "    data = df.as_matrix()\n",
    "\n",
    "    X = data[:,:-1]\n",
    "    Y = data[:,-1]\n",
    "\n",
    "    # normalize columns 1 and 2\n",
    "    X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()\n",
    "    X[:,2] = (X[:,2] - X[:,2].mean()) / X[:,2].std()\n",
    "\n",
    "    # create a new matrix X2 with the correct number of columns\n",
    "    N, D = X.shape\n",
    "    X2 = np.zeros((N, D+3))\n",
    "    X2[:,0:(D-1)] = X[:,0:(D-1)] # non-categorical\n",
    "\n",
    "    # one-hot\n",
    "    for n in range(N):\n",
    "        t = int(X[n,D-1])\n",
    "        X2[n,t+D-1] = 1\n",
    "\n",
    "    # method 2\n",
    "    # Z = np.zeros((N, 4))\n",
    "    # Z[np.arange(N), X[:,D-1].astype(np.int32)] = 1\n",
    "    # # assign: X2[:,-4:] = Z\n",
    "    # assert(np.abs(X2[:,-4:] - Z).sum() < 1e-10)\n",
    "\n",
    "    return X2, Y\n",
    "\n",
    "\n",
    "def get_binary_data():\n",
    "    # return only the data from the first 2 classes\n",
    "    X, Y = get_data()\n",
    "    X2 = X[Y <= 1]\n",
    "    Y2 = Y[Y <= 1]\n",
    "    return X2, Y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:0.968571428571 Test accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X,Y=get_data(path)\n",
    "X,Y=shuffle(X,Y)\n",
    "Ntrain=int(.7*len(X))\n",
    "Xtrain,Ytrain=X[:Ntrain],Y[:Ntrain]\n",
    "Xtest,Ytest=X[Ntrain:],Y[Ntrain:]\n",
    "model=MLPClassifier(hidden_layer_sizes=(5,5),max_iter=2000)\n",
    "model.fit(Xtrain,Ytrain)\n",
    "\n",
    "train_acc=model.score(Xtrain,Ytrain)\n",
    "test_acc=model.score(Xtest,Ytest)\n",
    "print(\"Train accuracy:\" +str(train_acc)+\" Test accuracy: \"+str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def init_weight_and_bias(M1, M2): #input size and output size\n",
    "    W = np.random.randn(M1, M2) / np.sqrt(M1+M2) #more weights you have, closer to zero they start\n",
    "    b = np.zeros(M2)\n",
    "    return W.astype(np.float32), b.astype(np.float32)\n",
    "\n",
    "def init_filter(shape, poolsz):#used for conv nn\n",
    "    #Shape is a tuple of 4 values (reason?)and we divide by the sqrt\n",
    "    # of fan size in times fan size out like with the weights\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[1:]) + shape[0]*np.prod(shape[2:] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    return 0\n",
    "def sigmoid(A):\n",
    "    return 1 / (1 + np.exp(-A))\n",
    "\n",
    "\n",
    "def softmax(A):\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def sigmoid_cost(T, Y):#calulates cross entropy from definition \n",
    "    #for sigmoid binary class\n",
    "    return -(T*np.log(Y) + (1-T)*np.log(1-Y)).sum()\n",
    "\n",
    "def cost(T, Y): #cross entropy for more than 2 classes\n",
    "    return -(T*np.log(Y)).sum()\n",
    "\n",
    "\n",
    "def cost2(T, Y):\n",
    "    # same as cost(), just uses the targets to index Y\n",
    "    # instead of multiplying by a large indicator matrix with mostly 0s\n",
    "    N = len(T)\n",
    "    return -np.log(Y[np.arange(N), T]).mean()\n",
    "\n",
    "\n",
    "def error_rate(targets, predictions):\n",
    "    return np.mean(targets != predictions)\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    K = len(set(y))\n",
    "    ind = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "\n",
    "def getData(path,balance_ones=True):\n",
    "    # images are 48x48 = 2304 size vectors\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(path+'fer2013.csv'):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0])) #label\n",
    "            X.append([int(p) for p in row[1].split()])#pixels space sep\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y) #scale and convert to array\n",
    "\n",
    "    if balance_ones: #balance classes through repetition\n",
    "        # balance the 1 class\n",
    "        X0, Y0 = X[Y!=1, :], Y[Y!=1]\n",
    "        X1 = X[Y==1, :]\n",
    "        X1 = np.repeat(X1, 9, axis=0)\n",
    "        X = np.vstack([X0, X1])\n",
    "        Y = np.concatenate((Y0, [1]*len(X1)))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def getImageData(): #r\n",
    "    X, Y = getData()\n",
    "    N, D = X.shape\n",
    "    d = int(np.sqrt(D))\n",
    "    X = X.reshape(N, 1, d, d) #N samples one color channel, width and height\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def getBinaryData(path):\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(path+'fer2013.csv'):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            y = int(row[0])\n",
    "            if y == 0 or y == 1:\n",
    "                Y.append(y)\n",
    "                X.append([int(p) for p in row[1].split()])\n",
    "    return np.array(X) / 255.0, np.array(Y)\n",
    "\n",
    "\n",
    "def crossValidation(model, X, Y, K=5):\n",
    "    # split data into K parts\n",
    "    X, Y = shuffle(X, Y)\n",
    "    sz = len(Y) // K\n",
    "    errors = []\n",
    "    for k in range(K):\n",
    "        xtr = np.concatenate([ X[:k*sz, :], X[(k*sz + sz):, :] ])\n",
    "        ytr = np.concatenate([ Y[:k*sz], Y[(k*sz + sz):] ])\n",
    "        xte = X[k*sz:(k*sz + sz), :]\n",
    "        yte = Y[k*sz:(k*sz + sz)]\n",
    "\n",
    "        model.fit(xtr, ytr)\n",
    "        err = model.score(xte, yte)\n",
    "        errors.append(err)\n",
    "    print(\"errors:\", errors)\n",
    "    return np.mean(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
