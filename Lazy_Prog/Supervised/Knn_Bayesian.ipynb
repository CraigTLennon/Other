{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods \n",
    "We will be using sqaured error as our cost function.\n",
    "\n",
    "$$\n",
    "V(s) \\leftarrow  V(s) + \\alpha \\left( G_s - V(s) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN is simple.  Once a metric is chosen, you examine all points in the training set to determine which k are closest to the test point.  The choose the label most prevelent among those k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "\n",
    "\n",
    "#Defining the class to have fit and predict functions like scikit-learn\n",
    "class KNN(object):\n",
    "    def __init__(self,k):\n",
    "        self.k=k\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def predict(self,Xtest):\n",
    "        y=np.zeros(len(Xtest))\n",
    "        for i,x in enumerate(Xtest): #returns a count and object of the iterable\n",
    "            sl=SortedList(load=self.k) #from sorted containers, a sorted list that will make it easy\n",
    "            #to track distances\n",
    "            for j,xt in enumerate(self.x): #this is training X\n",
    "                diff=x-xt\n",
    "                d=diff.dot(diff) #dot product\n",
    "                if len(sl)<self.k:\n",
    "                    sl.add((d,self.y[j])) #add the distance and the class\n",
    "                else:\n",
    "                    if d<sl[-1][0]:\n",
    "                        del sl[-1]\n",
    "                        sl.add((d,self.y[j])) \n",
    "                #at the end of this for loop we have the k closest elements\n",
    "            votes={}\n",
    "            for _,v in sl: # v is the vote for a class\n",
    "                votes[v]=votes.get(v,0)+1\n",
    "                max_vote=0\n",
    "                max_class=-1\n",
    "                for v,count in votes.items():\n",
    "                    if count >max_vote:\n",
    "                        max_vote=count\n",
    "                        max_class=v\n",
    "                        \n",
    "                y[i]=max_class\n",
    "        return(y)\n",
    "                \n",
    "    def score(self,x,y):\n",
    "        p=self.predict(x)\n",
    "\n",
    "        return( np.mean(p==y))\n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=\"C:/Users/craig_arl/Documents/GitHub/machine_learning_examples/mnist_csv/\"\n",
    "xtrn=data_folder+\"Xtrain.txt\"\n",
    "xtest=data_folder+\"Xtest.txt\"\n",
    "ytrn=data_folder+\"label_train.txt\"\n",
    "ytest=data_folder+\"label_test.txt\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "def get_data(f_name_X,f_name_Y,limit=None):\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    df_x = pd.read_csv(f_name_X)\n",
    "    df_y = pd.read_csv(f_name_Y)\n",
    "    df=df_y.join(df_x)\n",
    "   \n",
    "    data = df.as_matrix()\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:] / 255.0 # data is from 0..255\n",
    "    Y = data[:, 0]\n",
    "    if limit is not None:\n",
    "        X, Y = X[:limit], Y[:limit]\n",
    "    return X, Y\n",
    "\n",
    "#copied:\n",
    "def get_xor():\n",
    "    X = np.zeros((200, 2))\n",
    "    X[:50] = np.random.random((50, 2)) / 2 + 0.5 # (0.5-1, 0.5-1)\n",
    "    X[50:100] = np.random.random((50, 2)) / 2 # (0-0.5, 0-0.5)\n",
    "    X[100:150] = np.random.random((50, 2)) / 2 + np.array([[0, 0.5]]) # (0-0.5, 0.5-1)\n",
    "    X[150:] = np.random.random((50, 2)) / 2 + np.array([[0.5, 0]]) # (0.5-1, 0-0.5)\n",
    "    Y = np.array([0]*100 + [1]*100)\n",
    "    return X, Y\n",
    "\n",
    "def get_donut():\n",
    "    N = 200\n",
    "    R_inner = 5\n",
    "    R_outer = 10\n",
    "\n",
    "    # distance from origin is radius + random normal\n",
    "    # angle theta is uniformly distributed between (0, 2pi)\n",
    "    R1 = np.random.randn(N//2) + R_inner\n",
    "    theta = 2*np.pi*np.random.random(N//2)\n",
    "    X_inner = np.concatenate([[R1 * np.cos(theta)], [R1 * np.sin(theta)]]).T\n",
    "\n",
    "    R2 = np.random.randn(N//2) + R_outer\n",
    "    theta = 2*np.pi*np.random.random(N//2)\n",
    "    X_outer = np.concatenate([[R2 * np.cos(theta)], [R2 * np.sin(theta)]]).T\n",
    "\n",
    "    X = np.concatenate([ X_inner, X_outer ])\n",
    "    Y = np.array([0]*(N//2) + [1]*(N//2))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "   0  -2.5633  -0.62572    0.9354    1.6618  -0.97179    0.3452  -0.086273  \\\n",
      "0  0  -3.4637  -0.88703  0.748670  1.434500  -1.15260  0.751390   0.507230   \n",
      "1  0  -2.0966  -0.25018  0.042457  1.900700  -2.52000  0.776630   0.797510   \n",
      "2  0  -1.6135  -0.59420  1.533200  1.466300  -0.49371  0.579620   0.018415   \n",
      "3  0  -2.9356  -1.23560 -0.510630  0.046622  -0.16494 -1.468300   1.501300   \n",
      "4  0  -4.0263  -0.96807  0.759960  2.724000  -0.14465 -0.077638   0.565700   \n",
      "\n",
      "   0.87996  -0.46192    ...        0.4244  -0.30342  -0.41417  -0.57815  \\\n",
      "0 -0.40091  -0.12550    ...     -0.039145  -0.64153 -0.268930 -0.809140   \n",
      "1  0.24791  -0.22920    ...      0.286230  -0.92112  0.130000 -0.688510   \n",
      "2  0.77533  -1.65060    ...      0.786620   0.26431 -0.071850  0.062487   \n",
      "3 -0.36378  -0.42991    ...      0.883280   0.87492 -0.065224 -0.576910   \n",
      "4 -0.77676  -1.16410    ...      0.251960   0.14318 -0.432150 -0.205540   \n",
      "\n",
      "     1.1077  -0.21329    0.154   0.11203   0.18448  -0.093481  \n",
      "0  1.053100 -0.171460  0.24931  0.326980  0.193540  -0.474850  \n",
      "1  0.676070  0.380990 -0.33922 -0.095522 -0.286310  -0.289570  \n",
      "2 -0.309330  0.305490  0.34620 -0.508830  0.139900   0.522820  \n",
      "3 -0.384170  0.588980 -0.97846  0.575420 -0.047799  -0.094497  \n",
      "4 -0.076072 -0.015377  1.00780  0.063510  0.961080  -0.399360  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Reading in and transforming data...\n",
      "   0  -3.7361  -0.50598   1.5505  -0.21144    -1.331  0.15785      1.29  \\\n",
      "0  0  -2.8598  -0.79404 -0.58453 -0.071963  0.106530 -0.96736  0.804820   \n",
      "1  0  -2.0248  -0.31111  1.49800  1.810000 -0.557550  0.57453  0.008184   \n",
      "2  0  -1.7868  -0.30369 -0.48574  1.087800 -1.669900  0.50183  0.724410   \n",
      "3  0  -3.4150  -0.29351  1.79870  2.427600  0.091691  0.13246  0.520240   \n",
      "4  0  -5.7953  -0.39618  1.72810  1.322400 -1.511100  0.16704  1.818700   \n",
      "\n",
      "   -0.21137  -0.093135    ...     -0.59622  0.59524  0.14981   0.61427  \\\n",
      "0  -0.84818   -0.10991    ...     0.134500  1.07290  0.35133 -0.031616   \n",
      "1   0.47713   -1.01870    ...     0.697300  0.21529 -0.13460 -0.473650   \n",
      "2   0.18685   -0.89494    ...     0.150260 -1.23240 -0.32351 -0.826290   \n",
      "3   0.19115   -1.74440    ...     0.004116  0.74059 -0.65895  0.167170   \n",
      "4  -0.50043   -1.26320    ...     0.142760  0.86343  0.13875  0.301900   \n",
      "\n",
      "     1.0268   0.74283  0.26004  -0.24116  -0.090842   0.74336  \n",
      "0 -0.470770  0.643880 -0.18166  0.915720   0.201480  0.007816  \n",
      "1  0.303310  0.464130  0.25088 -0.618240   0.263590  0.848550  \n",
      "2  0.048414 -0.007641  0.44456 -0.060102  -0.028146 -0.345050  \n",
      "3 -0.104250  0.156280  0.65367 -0.249020   0.736460 -0.275260  \n",
      "4  0.347610  0.503080  0.45956  0.061204  -0.665110 -0.106540  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_data(xtrn,ytrn)\n",
    "x_test,y_test=get_data(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNN(5)\n",
    "knn.fit(x_train,y_train)\n",
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...,  True  True  True]\n",
      "[-1.5557   -0.056098  0.49028  ..., -1.1936   -0.41051  -2.1814  ] [-1.5557   -0.056098  0.49028  ..., -1.1936   -0.41051  -2.1814  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.998999799959992"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    def fit(self, x,y,smoothing=10e-3):\n",
    "        self.gaussians=dict()\n",
    "        self.priors=dict()\n",
    "        labels=set(y.astype(int))\n",
    "        \n",
    "        for c in labels:\n",
    "            current_x=x[y==c]\n",
    "            self.gaussians[c]={'mean':current_x.mean(axis=0),\n",
    "                              'var': current_x.var(axis=0)+smoothing} #axis 0 down 1 across\n",
    "            self.priors[c]=float(len(y[y==c]))/len(y)\n",
    "    def score(self,x,y):\n",
    "        p=self.predict(x)\n",
    "        return( np.mean(p==y))\n",
    "    \n",
    "    def predict(self,x):\n",
    "        N,D=x.shape\n",
    "        K=len(self.gaussians)\n",
    "        P=np.zeros((N,K)) #matrix for the probabilities of each class\n",
    "        for c,g in self.gaussians.items():\n",
    "         \n",
    "            mean,var = g['mean'],g['var']\n",
    "            P[:,c]=mvn.logpdf(x,mean=mean,cov=var)+np.log(self.priors[c])   #for each x prob it is class c\n",
    "        return(np.argmax(P,axis=1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "   0  -2.5633  -0.62572    0.9354    1.6618  -0.97179    0.3452  -0.086273  \\\n",
      "0  0  -3.4637  -0.88703  0.748670  1.434500  -1.15260  0.751390   0.507230   \n",
      "1  0  -2.0966  -0.25018  0.042457  1.900700  -2.52000  0.776630   0.797510   \n",
      "2  0  -1.6135  -0.59420  1.533200  1.466300  -0.49371  0.579620   0.018415   \n",
      "3  0  -2.9356  -1.23560 -0.510630  0.046622  -0.16494 -1.468300   1.501300   \n",
      "4  0  -4.0263  -0.96807  0.759960  2.724000  -0.14465 -0.077638   0.565700   \n",
      "\n",
      "   0.87996  -0.46192    ...        0.4244  -0.30342  -0.41417  -0.57815  \\\n",
      "0 -0.40091  -0.12550    ...     -0.039145  -0.64153 -0.268930 -0.809140   \n",
      "1  0.24791  -0.22920    ...      0.286230  -0.92112  0.130000 -0.688510   \n",
      "2  0.77533  -1.65060    ...      0.786620   0.26431 -0.071850  0.062487   \n",
      "3 -0.36378  -0.42991    ...      0.883280   0.87492 -0.065224 -0.576910   \n",
      "4 -0.77676  -1.16410    ...      0.251960   0.14318 -0.432150 -0.205540   \n",
      "\n",
      "     1.1077  -0.21329    0.154   0.11203   0.18448  -0.093481  \n",
      "0  1.053100 -0.171460  0.24931  0.326980  0.193540  -0.474850  \n",
      "1  0.676070  0.380990 -0.33922 -0.095522 -0.286310  -0.289570  \n",
      "2 -0.309330  0.305490  0.34620 -0.508830  0.139900   0.522820  \n",
      "3 -0.384170  0.588980 -0.97846  0.575420 -0.047799  -0.094497  \n",
      "4 -0.076072 -0.015377  1.00780  0.063510  0.961080  -0.399360  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Reading in and transforming data...\n",
      "   0  -3.7361  -0.50598   1.5505  -0.21144    -1.331  0.15785      1.29  \\\n",
      "0  0  -2.8598  -0.79404 -0.58453 -0.071963  0.106530 -0.96736  0.804820   \n",
      "1  0  -2.0248  -0.31111  1.49800  1.810000 -0.557550  0.57453  0.008184   \n",
      "2  0  -1.7868  -0.30369 -0.48574  1.087800 -1.669900  0.50183  0.724410   \n",
      "3  0  -3.4150  -0.29351  1.79870  2.427600  0.091691  0.13246  0.520240   \n",
      "4  0  -5.7953  -0.39618  1.72810  1.322400 -1.511100  0.16704  1.818700   \n",
      "\n",
      "   -0.21137  -0.093135    ...     -0.59622  0.59524  0.14981   0.61427  \\\n",
      "0  -0.84818   -0.10991    ...     0.134500  1.07290  0.35133 -0.031616   \n",
      "1   0.47713   -1.01870    ...     0.697300  0.21529 -0.13460 -0.473650   \n",
      "2   0.18685   -0.89494    ...     0.150260 -1.23240 -0.32351 -0.826290   \n",
      "3   0.19115   -1.74440    ...     0.004116  0.74059 -0.65895  0.167170   \n",
      "4  -0.50043   -1.26320    ...     0.142760  0.86343  0.13875  0.301900   \n",
      "\n",
      "     1.0268   0.74283  0.26004  -0.24116  -0.090842   0.74336  \n",
      "0 -0.470770  0.643880 -0.18166  0.915720   0.201480  0.007816  \n",
      "1  0.303310  0.464130  0.25088 -0.618240   0.263590  0.848550  \n",
      "2  0.048414 -0.007641  0.44456 -0.060102  -0.028146 -0.345050  \n",
      "3 -0.104250  0.156280  0.65367 -0.249020   0.736460 -0.275260  \n",
      "4  0.347610  0.503080  0.45956  0.061204  -0.665110 -0.106540  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "[ 1.  0.  1. ...,  3.  6.  0.]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=get_data(xtrn,ytrn)\n",
    "x_test,y_test=get_data(xtest,ytest)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71342685370741488"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NaiveBayes()\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
