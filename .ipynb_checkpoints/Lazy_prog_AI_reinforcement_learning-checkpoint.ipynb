{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for Artificial Intelligence:  Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epsilon-greedy is a simple solution to the explore exploit dilemma, in which you choose a small number epsilon as the probability of exploration (maybe 5-10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pseudo code p = random()\n",
    "if p< eps\n",
    "    pull random arm\n",
    "else pull current-best arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rand\n",
    "def bandits(i):\n",
    "    if i<=0:\n",
    "        return rand.uniform(-1,1)\n",
    "    elif i<=1:\n",
    "        return rand.uniform(-.25,1)\n",
    "    else:\n",
    "        return rand.uniform(-2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.536886980770646, 36267.32956034219, -826.88887455829]\n",
      "[0.006216448828508447, 0.3753177467378423, -0.4939596060924038]\n",
      "[1695.001, 96631.001, 1674.001]\n"
     ]
    }
   ],
   "source": [
    "reward=[0,0,0]\n",
    "count=0\n",
    "tries=[.001,.001,.001]\n",
    "mean=[0.0,0.0,0.0]\n",
    "\n",
    "bandit = rand.randint(0,2)\n",
    "while count <100000:\n",
    "    p=rand.uniform(0,1)\n",
    "    if p<.05:\n",
    "        bandit = rand.randint(0,2)\n",
    "    else:\n",
    "        bandit =mean.index(max(mean))\n",
    "    #print(bandit)    \n",
    "    reward[bandit]+=bandits(bandit)\n",
    "    tries[bandit]+=1\n",
    "    mean=[ reward[i]/tries[i] for i in range(3)]\n",
    "    count+=1\n",
    "print(reward)\n",
    "print(mean)\n",
    "print(tries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative mean update xn=(1-1/n)xn+x_new/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8314320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LP implementation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Bandit:\n",
    "    def __init__(self,m,initMean=0.0):\n",
    "        self.m=m\n",
    "        self.mean=initMean\n",
    "        self.N=0\n",
    "        \n",
    "\n",
    "    def pull(self):\n",
    "        return np.random.randn()+self.m\n",
    "    \n",
    "    def update(self,x):\n",
    "        self.N+=1\n",
    "        self.mean=(1-1.0/self.N)*self.mean+x*1.0/self.N\n",
    "        \n",
    "def run_experiments(m1,m2,m3,eps,N,initMean=10.0):\n",
    "    bandits=[Bandit(m1),Bandit(m2),Bandit(m3)]\n",
    "    \n",
    "    data=np.empty(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        p=rand.uniform(0,1)\n",
    "        if p<.05:\n",
    "            bd = np.random.choice(3)\n",
    "        else:\n",
    "            bd =np.argmax([b.mean for b in bandits])\n",
    "        x=bandits[bd].pull()\n",
    "        bandits[bd].update(x)\n",
    "        data[i]=x\n",
    "    cum_avg=np.cumsum(data)/ (np.arange(N)+1)\n",
    "    plt.plot(cum_avg)\n",
    "    plt.plot(np.ones(N)*m1)\n",
    "    plt.plot(np.ones(N)*m2)\n",
    "    plt.plot(np.ones(N)*m3)\n",
    "    plt.show()\n",
    "run_experiments(1,2,3,.1,1000,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCyHHO5mZjnkcDczyyGHu5lZDv1/6shjUHHCk5YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8559d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with optimistic initial values, we encourage exploration, examining a new resource until we have determined that\n",
    "#it is no good, above we added an initial mean value to the run experiment to allow for setting an optimistic initial value\n",
    "#Next UCB 1 (upper confidence bound) makes use of a chernoff bound (details?)\n",
    "#U_ucbj=mean_x_j+sqrt(2log(n)/nj) with n = # times played and nj = # times played bandit j and mean_x_j is mean for bandit j\n",
    "# we use if by being greedy with respect to this upper bound rather than sample mean\n",
    "# as nj's increase, the upper bounds shrink, so converges to a greedy strategy using the mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "import math\n",
    "class Bandit_UCB:\n",
    "    def __init__(self,m,initMean=0.0):\n",
    "        self.m=m\n",
    "        self.mean=initMean\n",
    "        self.N=1\n",
    "        \n",
    "\n",
    "    def pull(self):\n",
    "        return np.random.randn()+self.m\n",
    "    \n",
    "    def update(self,x):\n",
    "        self.N+=1\n",
    "        self.mean=(1-1.0/self.N)*self.mean+x*1.0/self.N\n",
    "        \n",
    "def run_experiments(m1,m2,m3,eps,N,initMean=0.0):\n",
    "    bandits=[Bandit_UCB(m1),Bandit_UCB(m2),Bandit_UCB(m3)]\n",
    "    \n",
    "    data=np.empty(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        p=rand.uniform(0,1)\n",
    "        if p< eps:\n",
    "            bd = np.random.choice(3)\n",
    "        else:\n",
    "            bd =np.argmax([b.mean+math.sqrt(2*math.log(i+1)/b.N) for b in bandits])#this is the line that differs\n",
    "        x=bandits[bd].pull()\n",
    "        bandits[bd].update(x)\n",
    "        data[i]=x\n",
    "    cum_avg=np.cumsum(data)/ (np.arange(N)+1)\n",
    "    plt.plot(cum_avg)\n",
    "    plt.plot(np.ones(N)*m1)\n",
    "    plt.plot(np.ones(N)*m2)\n",
    "    plt.plot(np.ones(N)*m3)\n",
    "    plt.show()\n",
    "run_experiments(1,2,3,0.0,10000,0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The basic Bayesian equation is posterior = liklihood times prior \n",
    "\n",
    "$p (\\theta | X) = \\frac{p(X \\cap \\theta)}{p(X)}=\\frac{p(X | \\theta) p(\\theta)}{\\int p(X|\\theta) p(\\theta) d\\theta}\\propto p(X | \\theta) p(\\theta)$\n",
    "\n",
    "Now to figure out the probability for a binomial X with N observations, we have \n",
    "$p(X | \\theta) = \\prod_{i=1}^n \\theta^X (1-\\theta)^{N-X}$.\n",
    "If we use a Beta distribution as a prior, then the result will be a beta distribution.  The pdf for a Beta(a,b) distribution is\n",
    "\n",
    "$p(\\theta)=\\frac{1}{B(a,b)} \\theta^{a-1} (1-\\theta)^{b-1},\\quad \\theta \\in (0,1),\\quad \\quad B(a,b):=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$\n",
    "\n",
    "Since we only care about proportionality, we can drop B(a,b) which would be absorbed into the normalization constant, so\n",
    "$p (\\theta | X) \\propto \\theta^{X+a-1}(1-\\theta)^{N-X+b-1}$\n",
    "\n",
    "Now we update the posterior to beta (a+#1s,b+#0s)\n",
    "\n",
    "For the multi-bandit case, we assume that data liklihood is Gaussian and that we base our decisions on the mean of each of the bandits, which is also Gaussian\n",
    "$X \\sim N(\\mu, \\tau^{-1}), \\quad \\mu \\sim N(m_0,\\lambda_0^{-1}).$  Assume Tau stays fixed and \"known\", but our samples for mu change as we draw observations based on the CLT.  $\\lambda_0^{-1} = \\tau^{-1} \\frac{1}{\\sqrt{n}}$\n",
    "\n",
    "Now for the update of $\\mu$:\n",
    "\n",
    "$$p(\\mu|X)\\propto \\left( \\prod_{j=1}^N \\frac{1}{\\sqrt{2\\pi / \\tau}} \\exp^{-\\tau \\,\\left( x_n-\\mu \\right)^2/2} \\right)\\frac{1}{\\sqrt{2 \\pi / \\lambda_0}} \\exp^{- \\lambda_0 \\,\\left( \\mu-m_0 \\right)^2/2}$$ To maximize wrt x, we drop teh fraction terms and consolidate into one exponential.\n",
    "$p(\\mu|X)\\propto \\exp \\left(- \\frac{\\lambda_0}{2} \\,\\left( \\mu-m_0 \\right)^2-\\frac{\\tau}{2} \\sum_{j=1}^N (x_j^2-2x_j\\mu+\\mu^2)  \\right)$\n",
    "After collecting like terms by $\\mu$, you get an equation you can use to update your posterior.\n",
    "$$\n",
    "-\\frac{1}{2} \\lambda \\left( \\mu - m \\right)^2 = -\\frac{1}{2}\\left(\\lambda \\mu^2-2m\\mu \\lambda \\dots \\right)\n",
    "$$\n",
    "now $\\lambda=\\lambda_0+\\tau N$ and $m \\lambda = m_0 \\lambda_0 + \\tau \\sum x_j$ and solve for $m$ to get \n",
    "$m=\\frac{m_0\\lambda_0+\\tau \\sum_j x_j}{\\lambda_0 +\\tau N}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34145079850492954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to program\n",
    "from scipy.stats import beta\n",
    "a_prior=1\n",
    "b_prior=1\n",
    "X=34\n",
    "N=100\n",
    "posterior=beta(a_prior+X,b_prior+N-X)\n",
    "posterior.rvs(1)\n",
    "posterior.rvs(1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfmOMCTMW+I0xJsxY4DfGmDDz/wEhdA32W67fiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb836d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class BayesianBandit:\n",
    "    \n",
    "    def __init__(self,m):\n",
    "        self.m=m #mu, which is now a random variable N(m0,)\n",
    "        self.m0=0 # mu prior\n",
    "        self.lambda0=1 #seems like precsion but updates as number of obs\n",
    "        self.sum_x=0 #used for calc posterior kept for convenience\n",
    "        self.tau =1 # inverse of variance\n",
    "        \n",
    "    def pull(self):\n",
    "        return np.random.randn()+self.m  #the result\n",
    "    \n",
    "    def sample(self):\n",
    "        return np.random.randn()/np.sqrt(self.lambda0)+self.m0 #generates sample from guassian with mean m0 and \n",
    "    #precision lambda0, recall that precision is the reciprocal of the variance.  The idea is that you are \n",
    "    #showing greater confidence in your mean estimate as you collect more samples.  Like CLT, except there should be variance.\n",
    "    #maybe assumtion is taht is is 1 and he's left that out since it is the default.\n",
    "    \n",
    "    def update(self, x):\n",
    "        self.lambda0+=1\n",
    "        self.sum_x+=x\n",
    "        self.m0=(self.sum_x/self.lambda0)*self.tau\n",
    "        \n",
    "def run_decay_eps_experiment(m1,m2,m3,N):\n",
    "    bandits=[Bandit(m1),Bandit(m2),Bandit(m3)]\n",
    "    \n",
    "    data=np.empty(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        p=rand.uniform(0,1)\n",
    "        if p< 1.0/(i+1): #decaying eps here\n",
    "            bd = np.random.choice(3)\n",
    "        else:\n",
    "            bd =np.argmax([b.mean for b in bandits])\n",
    "        x=bandits[bd].pull()\n",
    "        bandits[bd].update(x)\n",
    "        data[i]=x\n",
    "    cum_avg=np.cumsum(data)/ (np.arange(N)+1)\n",
    "#     plt.plot(cum_avg)\n",
    "#     plt.plot(np.ones(N)*m1)\n",
    "#     plt.plot(np.ones(N)*m2)\n",
    "#     plt.plot(np.ones(N)*m3)\n",
    "#     plt.xscale('log')\n",
    "#     plt.show()\n",
    "    return cum_avg\n",
    "\n",
    "def run_bayes_experiment(m1,m2,m3,N):\n",
    "    bandits=[BayesianBandit(m1),BayesianBandit(m2),BayesianBandit(m3)]\n",
    "    \n",
    "    data=np.empty(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        bd =np.argmax([b.sample() for b in bandits])\n",
    "        x=bandits[bd].pull()\n",
    "        bandits[bd].update(x)\n",
    "        data[i]=x\n",
    "    cum_avg=np.cumsum(data)/ (np.arange(N)+1)\n",
    "#     plt.plot(cum_avg)\n",
    "#     plt.plot(np.ones(N)*m1)\n",
    "#     plt.plot(np.ones(N)*m2)\n",
    "#     plt.plot(np.ones(N)*m3)\n",
    "#     plt.xscale('log')\n",
    "#     plt.show()\n",
    "    return cum_avg\n",
    "eps=run_decay_eps_experiment(1,2,3,100000)\n",
    "bay=run_bayes_experiment(1,2,3,100000)\n",
    "plt.plot(eps,label='decaying-epsilon-greedy',color='red')\n",
    "plt.plot(bay,label='Bayesian',color='green')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "State Action Reward notation at time t\n",
    "\n",
    "State at time t $S(t)$, Action at time t is $A(t)$\n",
    "\n",
    "This action results in a new state and reward at time t+1, $S(t+1), \\, R(t+1)$\n",
    "\n",
    "Sometimes expressed as tuple $(s,a,r,s^\\prime)$ where $s^\\prime$ is the new state at time t+1, $r$ is reward we get at time $t+1$.\n",
    "An \"Episode\" is one run of the game, and is different from a continuous task which never ends.\n",
    "\n",
    "\"Terminal state\" is a state at which the episode ends.\n",
    "\n",
    "Example problem:  \"cart pull\" / \"inverted pendulum\"\n",
    "There is an unstable system, and the episode starts with the pole vertical, then it falls.  The agent moves to keep the pole within a certain angle, and any angle past that is terminal.  This requires an infinite # of states, because state space is continuous, althoug the task is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning rewards:\n",
    "\n",
    "Maze example, reward of -1 for each step, and positive reward for exiting maze.  Tell the agent what you want it to achieve, not how to do it.\n",
    "Value function assigns value to the current state that reflects the future too.\n",
    "\n",
    "The credit assignment problem is the problem of properly distributing rewards over actions.  What action gets teh credit?  This is a problem of assigning credit to the past.\n",
    "Delayed rewards is the problem of assigning credit to the future (planning).\n",
    "One way is to use the expected value of a state given future values (but how to know without seeing all states).\n",
    "So value function can be thought of as the value of a state taking into account all future rewards.\n",
    "Value of State is the measure of possible future rewards you may get, while the reward is what you get immediately upon entering the state.  Thus value function is great if you can find it, but not all RL requires estimating value function. Some computations:\n",
    "$$\n",
    "V(s)= E \\left[\\textrm{ all future rewards } | \\, S(t)=s \\right]\n",
    "$$\n",
    "\n",
    "To find $V(S),$ initialize $V(S)$ as 1 if s is a winning state, 0 if s is lose or draw, and 0.5 otherwise.\n",
    "The update equation relies on playing the game, keeping track of all states you were in, and then assigning credit from last to first via $V(s_i) \\leftarrow V(s_i)+ \\alpha \\left( V(s_{i+i}) - V(s_i) \\right)$ \n",
    "\n",
    "The terminal state is never updated since it has no next state (and doesn't need to be anyway).  Repeat over many episodes.\n",
    "\n",
    "Note you could do this for FACS by having one array per emotion.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, None, None], [None, None, None], [None, None, None]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for t in range(max_iterations):\n",
    "#     state_history=playgame #list\n",
    "#     s=state_history[0]\n",
    "#     for state in state_history[1:]:\n",
    "#         V(s) = V(s)+ learning_rate * (V(state)-V(s))\n",
    "#         s=state\n",
    "#since we have a value function we could play as follows\n",
    "# maxV=0\n",
    "# maxA=None\n",
    "# for a,state in possible_states:\n",
    "#     if V(state) > maxV:\n",
    "#         maxV=V(state)\n",
    "#         maxA=a\n",
    "#     perform action maxA\n",
    "#But there is a problem with this, the exploit, explore dilemma.  Random actions lead us to states we have not visitied.\n",
    "#This improves our value estimate for these states.\n",
    "#So we could use epsilon-greedy approach, choosing a random action state in possible states\n",
    "3*[3*[None]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author suggests using an array indexed in a trinary fashion: $D=3^{n-1}t_{n-1}+ \\dots + 3t_1+t_0$  My original idea was to use a lists of lists, which would have made it hard to keep track of all the states and their values.  While the current state might have been depicted well by a list of lists, that's a bad way to store states for learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "length=3\n",
    "\n",
    "\n",
    "def play_game(p1,p2,env,draw=False):\n",
    "    current_player=None\n",
    "    counter =0\n",
    "    \n",
    "    while not env.game_over():\n",
    "        print(counter)\n",
    "        counter+=1\n",
    "        if current_player ==p1:\n",
    "            current_player=p2\n",
    "        else:\n",
    "            current_player=p1\n",
    "        if draw:\n",
    "            env.draw_board()\n",
    "    #         if draw ==1 and current_player==p1:\n",
    "    #             env.draw_board()\n",
    "    #         if draw ==2 and current_player==p2:\n",
    "    #             env.draw_board()\n",
    "        current_player.take_action(env)\n",
    "        state = env.get_state()\n",
    "        p1.update_state_history(state) #add current states to history\n",
    "        p2.update_state_history(state)\n",
    "    p1.update(env) # update value function after every game\n",
    "    p2.update(env)\n",
    "    if draw:\n",
    "        env.draw_board()\n",
    "\n",
    "class Environment():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.board=np.zeros((length,length)) # 0 is empty\n",
    "        self.x=-1\n",
    "        self.o=1\n",
    "        self.winner=None\n",
    "        self.ended=False\n",
    "        self.num_states=3**(length**2)\n",
    "\n",
    "    def is_empty(self,i,j):\n",
    "        return self.board[i,j]==0\n",
    "    def reward(self,sym):\n",
    "        if not self.game_over():\n",
    "            return 0\n",
    "        if self.winner==sym:\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    def game_over(self, force_recalculate=False):\n",
    "        if not force_recalculate and self.ended:\n",
    "            return self.ended\n",
    "        for i in range(length): #check rows\n",
    "            for player in (self.x,self.o):\n",
    "                if self.board[i,:].sum() == player*length:\n",
    "                    self.winner = player\n",
    "                    self.ended =True\n",
    "                    return True\n",
    "        for j in range(length): #check columns\n",
    "            for player in (self.x,self.o):\n",
    "                if self.board[:,j].sum() == player*length:\n",
    "                    self.winner = player\n",
    "                    self. ended =True\n",
    "                    return True\n",
    "        for player in (self.x,self.o):\n",
    "            if self.board.trace() == player*length:\n",
    "                self.winner = player\n",
    "                self. ended =True\n",
    "                return True\n",
    "            if np.fliplr(self.board).trace() == player*length:\n",
    "                self.winner = player\n",
    "                self. ended =True\n",
    "                return True\n",
    "        #draw\n",
    "        if np.all((self.board==0)==False):\n",
    "            self.winner = None\n",
    "            self.ended=True\n",
    "            return True\n",
    "        \n",
    "        self.winner=None\n",
    "        return False\n",
    "    \n",
    "    def is_draw(self):\n",
    "        return self.ended and welf.winner is None\n",
    "        \n",
    "    def draw_board(self):\n",
    "        print(self.board)\n",
    "        for i in range(length):\n",
    "            print(\"------------\")\n",
    "            for j in range(length):\n",
    "                print(\" |\",end='')\n",
    "                if self.board[i,j]==self.x:\n",
    "                    print(\"x\",end='')\n",
    "                elif self.board[i,j]==self.o:\n",
    "                    print(\"o\",end='')\n",
    "                else:\n",
    "                    print(\" \",end='')\n",
    "            print(\"\")\n",
    "        print(\"------------\")\n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "    def get_state(self):\n",
    "        k=0\n",
    "        h=0\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                if self.board[i,j]==0:\n",
    "                    v=0\n",
    "                elif self.board[i,j]==self.x:\n",
    "                    v=1\n",
    "                elif self.board[i,j]==self.o:\n",
    "                    v=2\n",
    "                h+=(3**k) * v\n",
    "                k+=1\n",
    "        return h\n",
    "\n",
    "\n",
    "def initialV_x(env,state_winner_triples):\n",
    "    #if x wins set 1, if lose draw set 0, else set 0.5\n",
    "    V=np.zeros(env.num_states)\n",
    "    for state,winner,ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner ==env.x:\n",
    "                v=1\n",
    "            else:\n",
    "                v=0\n",
    "        else:\n",
    "            v=0.5\n",
    "        V[state]=v\n",
    "    return V\n",
    "\n",
    "def initialV_o(env,state_winner_triples):\n",
    "    #if x wins set 1, if lose draw set 0, else set 0.5\n",
    "    V=np.zeros(env.num_states)\n",
    "    for state,winner,ended in state_winner_triples:\n",
    "        if ended:\n",
    "            if winner ==env.o:\n",
    "                v=1\n",
    "            else:\n",
    "                v=0\n",
    "        else:\n",
    "            v=0.5\n",
    "        V[state]=v\n",
    "    return V\n",
    "\n",
    "def get_state_hash_and_winner(env,i=0,j=0):#returns (state,winner,game_over)\n",
    "    #state is configuration of board as hashed\n",
    "    #winner None unless ended false\n",
    "    results=[]\n",
    "    for v in (0,env.x,env.o):\n",
    "        env.board[i,j]=v\n",
    "#         print(\"i \"+str(i)+\" j \"+str(j))\n",
    "        if j==2:\n",
    "            if i==2:\n",
    "                state=env.get_state()\n",
    "                ended=env.game_over(force_recalculate=True)\n",
    "                winner = env.winner\n",
    "                results.append((state,winner,ended))\n",
    "            else:\n",
    "                results+=get_state_hash_and_winner(env,i+1,0)#j restarts at 0\n",
    "        else:\n",
    "            results+=get_state_hash_and_winner(env,i,j+1)#j restarts at 0\n",
    "\n",
    "    return results\n",
    "    \n",
    "##########\n",
    "class Human:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_symbol(self,sym):\n",
    "        self.sym=sym\n",
    "    \n",
    "    def take_action(self,env):\n",
    "        while True:\n",
    "            move=input(\"Enter coordinates i,j for next move (0<=i,j<=2)\")\n",
    "            i,j=move.split(',')\n",
    "            i = int(i)\n",
    "            j=int(j)\n",
    "            \n",
    "            if env.is_empty(i,j):\n",
    "                env.board[i,j]=self.sym\n",
    "                break\n",
    "    def update(self,env):\n",
    "        pass\n",
    "    def update_state_history(self,s):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    \n",
    "    def __init__(self,eps=.1,alpha=.5):\n",
    "        self.eps=eps\n",
    "        self.alpha=alpha\n",
    "        self.verbose = False\n",
    "        self.state_history=[]\n",
    "        \n",
    "    def update(self, env):\n",
    "        reward= env.reward(self.sym) #didn't see rewarad method in environment\n",
    "        target = reward\n",
    "        for prev in reversed(self.state_history):\n",
    "            value = self.V[prev]+self.alpha*(target - self.V[prev])\n",
    "            self.V[prev]=value\n",
    "            target=value\n",
    "        self.reset_history()\n",
    "        \n",
    "    def setV(self,V):\n",
    "        self.V=V\n",
    "        \n",
    "        \n",
    "    def set_symbol(self,sym):\n",
    "        self.sym=sym\n",
    "        \n",
    "    def set_verbose(self,v):\n",
    "        self.verbose=v\n",
    "        \n",
    "    def reset_history(self):\n",
    "        self.state_history=[]\n",
    "    \n",
    "    def update_state_history(self,s):\n",
    "        self.state_history.append(s)\n",
    "    \n",
    "    def take_action(self,env):\n",
    "        r = np.random.rand()\n",
    "        best_state=None\n",
    "        \n",
    "        if r<self.eps:\n",
    "            if self.verbose:\n",
    "                print(\"take random action\")\n",
    "            possible_moves=[]  #list of tupels (i,j)\n",
    "\n",
    "            for i in range(length):\n",
    "                for j in range(length):\n",
    "                    if env.is_empty(i,j):\n",
    "                        possible_moves.append((i,j))\n",
    "            idx = np.random.choice(len(possible_moves))\n",
    "            next_move=possible_moves[idx]\n",
    "        else:\n",
    "            pos2value = {} # for debugging\n",
    "            next_move=None\n",
    "            best_value=-1\n",
    "            for i in range(length):\n",
    "                for j in range(length):\n",
    "                    if env.is_empty(i,j):\n",
    "                        env.board[i,j]=self.sym\n",
    "                        state = env.get_state()\n",
    "                        env.board[i,j]=0\n",
    "                        pos2value[(i,j)] = self.V[state]\n",
    "                        if self.V[state]>best_value:\n",
    "                            best_value=self.V[state]\n",
    "                            best_state=state\n",
    "                            next_move=(i,j)\n",
    "                        \n",
    "        if self.verbose:\n",
    "            print( \"Taking a greedy action\")\n",
    "            for i in xrange(LENGTH):\n",
    "                print(\"\")  \n",
    "                print(\"-----------------\")\n",
    "                for j in xrange(LENGTH):\n",
    "                    if env.is_empty(i, j):\n",
    "                        print(\"%.2f|\" % pos2value[(i,j)],end='')\n",
    "                    else:\n",
    "                        print( \" |\",end='')\n",
    "                        if env.board[i,j] == env.x:\n",
    "                            print( \"x|\",end='')\n",
    "                        elif env.board[i,j] == env.o:\n",
    "                            print( \"o|\",end='')\n",
    "                        else:\n",
    "                            print( \" |\",end='')\n",
    "            print(\"\")\n",
    "            print( \"-----------------\")\n",
    "\n",
    "    # make the move\n",
    "        env.board[next_move[0], next_move[1]] = self.sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1=Agent()\n",
    "p2=Agent()\n",
    "env = Environment()\n",
    "sw_triple=get_state_hash_and_winner(env,0,0)\n",
    "Vx=initialV_x(env,sw_triple)\n",
    "p1.setV(Vx)\n",
    "Vo=initialV_o(env,sw_triple)\n",
    "p2.setV(Vo)\n",
    "p1.set_symbol(env.x)\n",
    "p2.set_symbol(env.o)\n",
    "T=2\n",
    "for t in range(T):\n",
    "    if t% 200 ==0:\n",
    "        print(t)\n",
    "    play_game(p1,p2,Environment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human  = Human()\n",
    "human.set_symbol(env.o)\n",
    "while True:\n",
    "    play_game(p1,human,Environment(),draw=True)\n",
    "    answer = input(\"Play again? [y/n]\")\n",
    "    if answer and answer.lower()=='n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
